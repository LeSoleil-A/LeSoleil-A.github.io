---
layout: post
title:  "笔记《CS224N Project Report: From Note2Vec to Chord2Vec》"
date:   2021-10-05 21:42:00 +0800
categories: 音乐论文笔记
typora-root-url: ..\assets\img\1005
---



这篇文章的主要目标是为音乐音符与和弦找到一种合适的嵌入方法，将其有效表示为向量形式。本文的工作有两个主要的创新点：首先，将和弦中的“context notes”看成一个整体；并且，引入了泛音作为entry进行embedding。

<br>

### 摘要

<br>

【背景】

在音乐与自然语言之间，单独的音符就像是语言中的字母，而和弦就像是词语，但是音符与和弦之间的区别要比字母和词语的区别更加模糊。（由此展现了NLP问题与音符、和弦嵌入问题存在一致性与差异性）

【目标】

本文试图创作一种向量表示，可以将和弦表示为其组成音符的和，以完成和弦的有效嵌入。

【结果】

最终获得的嵌入向量在一些简单的音乐理论任务上进行了评估，证实了这些嵌入向量捕获了基本的音乐特性，可以表达意义丰富的音乐理论信息。

【未来】

未来，可以评估这些向量表示在现有的音乐生成模型中的应用有效性。

<br>

### 介绍

<br>

本文主要有两个目标，首先是将音乐和弦表示为嵌入向量，进一步是使用这些向量探索音乐生成模型。（现有的音乐生成模型成功地运用了基于 **self-attention** 的 **transformer** 进行音乐生成。从这篇文章来看，音乐生成模型这一目标并没有进行深入探索，所以本文的主要工作专注于和弦表示，以期能够辅助乐理学习乃至生成更准确的音乐）。

考虑到音乐与自然语言的相似性，本文从 *word2vec* 以及 *skip-gram* 模型获取灵感进行和弦嵌入，**以获取能够表示基本音乐概念的和弦嵌入形式**。与成千上万的自然语言单词比起来，音符的优势是只有88个，易提取音符间的关系。但是这种小体量也有缺点，相较于长度足够的语句来说，仅3-4个音符的和弦很难传递足够的信息。

【解决方法】

为了解决上述问题，本文使用了一种和弦的加和表示，并且引入了泛音，来强调和弦的关键音，关键音可以帮助本文的模型识别音乐理论概念。在使用这些改进方案之后，模型可以在**主/属和弦分类任务**以及**根和弦名称分类任务**上达到一个足够的准确度。

<br>

### 相关工作

<br>

#### Music Transformer

本文的主要启发来源。其优势为： *transformer* 的 *self-attention* 模型以及 *long-term memory* 可以生成与原始音乐几乎一模一样的音乐；模型的每一层都包含了一个**注意力亚层**和一个**foward亚层**，可以有效提取出最重要的音符。

#### word2vec

关于这一部分，有一些文献证明了学习和弦嵌入对于表示音乐和弦与乐理概念有积极作用。这些文献证明了和弦嵌入可以影响音乐音符的生成方向，并且对于五度圈等音乐概念给予更多的强调。**这些文献可以作为音乐嵌入论文的参考资料，用以证明和弦嵌入对于乐理表示、音乐生成的重要影响**。对于 *word2vec* 模型，本文分析了 *skipgram* 模型并且减弱了 *context window* 的概念。然而，处理自然语言的 *word2vec* 模型只能作为一个基础，要应用在和弦上还需要做出改进。

#### note2vec

*note2vec* 模型已有文献提出。其使用了 *skipgram* 模型，并且对贝多芬的奏鸣曲数据切片采用负采样。此项工作的优化目标是使得相似的（或者说最相关的）音符映射后拥有较小的 **cosine distance**。

#### LSTM

这一部分主要是关于音乐生成的。

<br>

### 方法

<br>

【核心思想】 **word2vec + music theory = 更好的音符表示模式**

#### Standard Note2Vec

直接将 *Word2Vec* 思想应用在音符上。所用的数据集由一系列包含3-4个音符的和弦构成，对于和弦中的**每一个音符**，我们使用 *SkipGram* 进行训练：将音符看作中心词（central “word”），其他的音符看作语境词（context “words”）。

此方法采用了**负采样**（negative sampling），每一个正样本（positive sample）对应一个负样本（negative sample）。

数据集总共包含52个不同的音符，所以本文将嵌入维度设置为4或8。

<br>

#### Note2Vec using Overtones

【本文的一个创新点】为了更好地将音符表示为向量，本文利用了**泛音**。

当一个音符 **N** 在乐器上弹奏时，**N+12** 、**N+19** 、**N+24** 、**N+28** 、**N+31** 、**N+34**、 **N+36**，······也可以被检测到。因此，通过52维的原始词汇表，我们可以创造88维的embeddings（这里感觉算是一种扩大数据集的预处理方式，看作embedding应该是会有主音和泛音重叠，所以算是一种映射），每一个音符**N**都有8个非零输入（N~N+36）。

<br>

#### Chord2Vec Superposition

【本文的一个创新点】将每一个和弦表示为其组成音符的重叠，即表示成其组成音符的向量和。

这一点主要是针对现有的音乐生成模型都是使用串行的音乐表示方法，将每一个和弦都表示为一系列不相关的音符。但是从听众的角度来说，和弦是音符的有机组成。

<br>

#### Note2Vec Averaged

【创新点的实现】（把和弦里面的context word看作一个整体）

使用88维的嵌入向量来训练 *Note2Vec* 模型，需要使用掩码（mask）来将每个音符的非零维度限制为其本身和它的泛音。对于一个映射方程 **E** 和和弦 **C = （C1，C2，C3， C4）**，其用于 *skip-gram* 的（word，context）对为\
$$
(E(C_i), \frac{Σ_{j≠i} E(C_j)}{3})_{i=1,2,3,4}
$$
\)。代表着音符的“context”是其“context notes”的平均值。

<br>

#### Chord2Vec Training

【创新点的实现】（把整个和弦看作一个整体，完成和弦与相邻和弦的嵌入）

对于任意相邻和弦**C<sub>n-1</sub>**、**C<sub>n</sub>**、**C<sub>n+1</sub>**，其中每一个**C<sub>k</sub> = （C<sub>k,1</sub>, C<sub>k,2</sub>, C<sub>k,3</sub>, C<sub>k,4</sub>）**。本文改造了skip-gram的和弦训练模式，选择context window的大小为1，则每一个用于训练的（word， context）对为：**（Σ<sub>i=1</sub>E(C<sub>k,i</sub>), Σ<sub>i=1</sub>E(C<sub>k-1,i</sub>)）**，**（Σ<sub>i=1</sub>E(C<sub>k,i</sub>), Σ<sub>i=1</sub>E(C<sub>k+1,i</sub>)）**。

这将每一个和弦表示为其组成音符的和，而*skip-gram*训练的损失会反向传播，以将每一个音符进行嵌入。这会使得嵌入模型能够更好地捕捉和弦间的相似性。

我认为这一步是*Note2vec*与*Chord2vec*的结合。首先，和弦被表示成为音符的和，接下来，训练过程中会对每一个音符进行嵌入，最终获得更好的和弦嵌入表达。虽然将和弦看作一个整体，但是没有忽略和弦中的单个音符。这种和弦整体与单个音符的兼顾值得更深入的学习，然而目前我并不清楚这是如何实现的。

<br>

#### Chord Classification

本文使用了一个CNN网络对获得的和弦嵌入进行评估，同时设置了一个one-hot编码的baseline model。

测试目标为：1. 判断一个和弦是主和弦还是属和弦；2. 将和弦的根音分类。

所使用的CNN模型包括一个单层的卷积层，包括64个通道，每一个的kernel size分别为13，10和7；以及一个dense network将数据处理为与输出通道数量一致；为了区分是主和弦还是属和弦，一个 *global max-pooling operation* 被使用进来，以识别和弦嵌入中所出现的特征。

![model](/assets/img/1005/model.PNG)

<br>

#### Music generation using LSTMs

本文使用 *Chord2Vec* 的嵌入结果以及 *bidirectional LSTM* 训练了一个语言模型，试图同时生成旋律与和弦，而不是像之前的工作那样，专注于串行生成。

在本文的工作中，尝试了许多使用 *attention* 的模型结构，但是都没有取得成功的生成效果。**之后如果有工作试图或者成功使用attention生成较好的音乐结果，可以引用此篇论文为未成功的相关工作。**

<br>

### 实验

<br>

#### 数据

【数据集名称及来源】JSB- Chorales-dataset from https://github.com/czhuang/JSB-Chorales-dataset。

【文件格式】pkl文件

【包含信息】音符（被表示为21-108之间的数字），在每个时间戳会有音符同时发声。

【训练集规模】总共有23,134个和弦。

【数据预处理】为了对和弦进行分类，本文生成了349个和弦，每一个都标注出了根音（被表示为一个0-11之间的数字）以及是主和弦还是属和弦。本文将这些和弦分为大小为174个和弦的训练集，以及大小为175个和弦的测试集。（没有验证集）

<br>

#### 评估方法

本文使用了标准 *skip-gram* 训练算法的 **L1 loss** 作为损失函数。和弦分类的准确性，由测试集中模型分类正确的和弦比例计算得出。

<br>

#### 实验细节

主要介绍了进行训练时的一些模型参数。

对于 *skip-gram chord2vec* ，学习率设为0.1，batch_size设为32，50个epochs，优化器使用标准SGD优化器。

对于和弦分类任务，学习率设为0.00001，batch_size设为1，50个epochs，带交叉熵损失的标准SGD。

对于LSTM音乐生成，学习率设为0.01，batch_size设为1，50个epochs，带L2损失的标准SGD。

<br>

#### 结果

实验表明，**基于泛音的和弦嵌入**相较于4维和8维的和弦嵌入产生了显著降低的训练损失，尤其是当把每一个“context chord”看作一个整体的时候。

为了验证这种和弦嵌入是否能够学得音乐的乐理，本文使用了神经网络以检验使用嵌入和弦是否能够区分出主和弦与属和弦、以及能否识别出和弦的根音：首先，将不同变换的主和弦与属和弦（root，first，and second）喂入神经网络，并且进行训练；接下来，使用测试集进行测试，并且记录准确度。

测试表明，相较于baseline，本文提出的 *Chord2Vec* 嵌入方法能够获得更高的测试准确率，不论是针对主和弦/属和弦分类任务还是根音分类任务。这表明本文的嵌入方法确实可以学得和弦之间的差异。

<br>

### 分析

<br>

首先是定量的分析，这一步包括评估 *Note2Vec* 模型。

首先，建立一个baseline。对于每一个关键音符，对其和弦中出现的音符计数。这一步能够找到与关键音符最常一起出现的音符。为了将嵌入后的音符与baseline进行比较，本文将嵌入后的音符进行映射，将其距离最接近的音符可视化。

![note](/assets/img/1005/note.PNG)

由统计结果看出，baseline方法成功找到了关键音符的五度及八度，这在音乐理论上是占重要地位的。而 *naive Note2Vec* 方法成功捕捉到了连续的音符，并且有效预测了哪些音符会在特定音符之后出现。然而，**因为 *naive Note2Vec* 方法只注意窗口内的音符，所以会导致对五度和八度的忽视**。因此，不利于获得一致的音乐理论结构。于是本文做出了这样的结论：**在预测下一音符与保持一个强乐理关系之间存在tradeoff** 。

然而，在**含泛音的Note2Vec方法**中，本文可以利用泛音来强调八度和五度关系，所以获得的音符与乐理规则极为相符。例如，可视化后，五度音符和八度音符较中心音符的距离很近。通过这种映射和寻找最近音符，本文证实了这种嵌入方式可以有效地标识出音乐的关键音符。

为了更好地展现出音符之间的关系，本文使用t-分布随机邻居嵌入（t-distribution stochastic neighbor embedding）将嵌入结果映射到了二维平面。在此平面上，可以直接观察到音符之间的 *relative cosine distance* 。

![TSNE](/assets/img/1005/TSNE.PNG)

通过左侧的TSNE平面图，可以看出具有相同音程（如五度）的音符对具有相似的距离。这证明 *Note2Vec* 学得了基于五度环的基本音乐理论。甚至可以看出相似的音符逐渐形成了聚类。

而右侧的平面图使用了较低的复杂度，展现了嵌入模型的聚类。可以看出此聚类是可预测的、并且普遍符合乐理。最重要的是，可以清晰地看出八度的分布：高八度围绕着低八度。通常来说，离中心越近，音符便属于越低的八度。这说明嵌入方法很好地表征了音符和乐理。

![DandG](/assets/img/1005/DandG.PNG)

接下来，**文章进一步探讨了为什么引入overtones**。

通过提取出G和D的平面图，可以看出两个音符之间存在相关关系，特别是相似的八度之间。比如G3到D3的向量就与G4到D4的向量十分相似。并且，“G5，G6"与”D5，D6“之间的向量几乎是一样的。这进一步证明了此嵌入方式提取乐理的质量。

而通过未引入泛音的 *Note2Vec* 模型与引入泛音的 *Note2Vec* 模型作比较，可以看出未引入泛音的模型中，音符之间的 *cosine distance* 是没有相关性的，分布呈现出随机状态。由此可以证明泛音的引入对于提取乐理中的重要音符有关键作用。

本文对于嵌入后的和弦也做了评估。选择了 **C, g, d, F** 几个 *focus chord* ，大写字母表示大调，小写字母表示小调。

![chord](/assets/img/1005/chord.PNG)

图表显示出，*Chord2Vec* 模型学得了一些基本的音乐理论。尤其值得注意的是，离“C Major”最近的有一个“a minor”，与“d# minor”最近的有一个“F# Major”，这些是具有相同音符特征的大小和弦。这说明本文的嵌入方式可以学得大小和弦之间的相似音符特征。

<br>

### 结论

<br>

本篇论文的工作展现了一个可以同时代表音乐音符及和弦的全新向量表示。本文展现出了，这些表示捕获了和弦最基本的特征，比如它们的根音以及他们是大和弦还是小和弦。对于单个音符最近邻的分析展现了结果与乐理规则的一致性。

<br>

### 未来工作

<br>

基于本文的嵌入方法，可以探索使用神经网络进行音乐生成。

<br>

### 后记

<br>

这篇文章的结构和语言非常清晰，可读性很强。文章最大的创新点是泛音的引入。此外，文章使用TSNE图来展现可视化结果，非常清晰直观，具有借鉴意义。这篇文章的代码仓库为https://github.com/philhchen/note2vec。

本文的相关工作值得作为拓展阅读，尤其是关于 *Note2Vec* 的那篇论文，似乎是这篇文章的重要基础，有助于对此文的更深刻理解。

